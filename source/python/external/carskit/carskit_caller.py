import json
import os
import subprocess
import uuid

import time

import collections

import jprops
import pandas

from etl import ETLUtils
from utils.constants import Constants

JAVA_COMMAND = 'java'
CARSKIT_JAR = 'CARSKit-v0.3.0.jar'
CARSKIT_ORIGINAL_CONF_FILE = Constants.CARSKIT_FOLDER + 'setting.conf'
CARSKIT_MODIFIED_CONF_FILE = Constants.CARSKIT_RATINGS_FOLDER + '%s.conf'
OUTPUT_FOLDER = Constants.DATASET_FOLDER + 'carskit_results/'


def run_carskit():

    jar_file = Constants.CARSKIT_FOLDER + 'jar/' + CARSKIT_JAR

    command = [
        JAVA_COMMAND,
        '-jar',
        jar_file,
        '-c',
        CARSKIT_MODIFIED_CONF_FILE % Constants.CARSKIT_RECOMMENDERS,
    ]

    print(command)

    unique_id = uuid.uuid4().hex
    log_file_name = Constants.GENERATED_FOLDER + Constants.ITEM_TYPE + '_' + \
        Constants.TOPIC_MODEL_TARGET_REVIEWS + '_parse_directory_' +\
        unique_id + '.log'

    log_file = open(log_file_name, 'w')
    p = subprocess.Popen(
        command, stdout=log_file, cwd=OUTPUT_FOLDER)
    p.wait()


def result_to_dict(result):
    """
    Takes one line from the results file generated by CARSKit and transforms it
    into a dictionary in the form of {'metric': value}. For instance a
    dictionary could be
    {'algorithm': 'svd', 'RMSE': 1.24, 'MAE': 0.9, 'num_factors': 10}

    :param result: the resulting dictionary with the information about the
    performance of the algorithm and the hyperparameters used
    """
    split_metrics = [metric.strip() for metric in result.split(',')]
    print(split_metrics)

    results_map = {}

    # Results from position 0 tell the algorithm
    algorithm = 'ck_' + split_metrics[0].split(' ')[-1].lower()
    results_map['ck_algorithm'] = algorithm

    unknown_count = 1

    for metric in split_metrics[1:-2]:
        metric_info = metric.split(': ')

        if len(metric_info) == 1:
            results_map[algorithm + str(unknown_count)] = metric_info[0]
            unknown_count += 1
        elif len(metric_info) == 2:
            results_map['ck_' + metric_info[0].lower()] = metric_info[1]
        else:
            print(metric_info)
            raise ValueError('Unrecognized results format')

    # Results from the last two positions tell the time
    results_map['ck_train_time'] = split_metrics[-2].split(': ')[1]
    results_map['ck_test_time'] = split_metrics[-1]

    return results_map


def save_results(results):

    # Take the results given by the run_carskit function and extend them with
    # the Constants.get_properties() dictionary, then save them to a CSV file

    """

    :type results: list[dict]
    :param results:
    """
    properties = Constants.get_properties_copy()

    json_file = Constants.generate_file_name(
        'carskit_results', 'json', OUTPUT_FOLDER, None, None, False)

    for result in results:
        result.update(properties)
        write_results_to_json(json_file, result)


def full_cycle():
    file_name = 'results_all_2016.txt'
    carskit_results_file = OUTPUT_FOLDER + file_name

    modify_properties_file()
    run_carskit()

    with open(carskit_results_file) as results_file:
        results = results_file.readlines()

    results_list = [result_to_dict(result) for result in results]
    save_results(results_list)

    # We remove the carskit results file because if not then we would be saving
    # the results from previous runs and we would have them duplicated
    os.remove(carskit_results_file)


def modify_properties_file():
    with open(CARSKIT_ORIGINAL_CONF_FILE) as read_file:
        properties = jprops.load_properties(read_file, collections.OrderedDict)

    recommender = Constants.CARSKIT_RECOMMENDERS
    modified_file = CARSKIT_MODIFIED_CONF_FILE % recommender
    properties['recommender'] = recommender
    properties['dataset.ratings.lins'] = \
        Constants.CARSKIT_RATINGS_FOLDER + 'ratings.csv'

    if Constants.CARSKIT_ITEM_RANKING:
        properties['item.ranking'] = 'on -topN 10'
    else:
        properties['item.ranking'] = 'off'

    with open(modified_file, 'w') as write_file:
        jprops.store_properties(write_file, properties)


def write_results_to_json(json_file, results):
    if not os.path.exists(json_file):
        with open(json_file, 'w') as f:
            json.dump(results, f)
            f.write('\n')
    else:
        with open(json_file, 'a') as f:
            json.dump(results, f)
            f.write('\n')


def analyze_results():
    json_file = Constants.generate_file_name(
        'carskit_results', 'json', OUTPUT_FOLDER, None, None, False)
    records = ETLUtils.load_json_file(json_file)

    data_frame = pandas.DataFrame(records)
    print(sorted(list(data_frame.columns.values)))
    data_frame = data_frame[['ck_rec10', 'ck_pre10', 'ck_algorithm', 'carskit_nominal_format']]
    data_frame = data_frame.sort_values(['ck_rec10'])
    print(data_frame)


def main():

    # modify_properties_file()
    # run_carskit()

    all_recommenders = [
        'globalavg', 'useravg', 'itemavg', 'useritemavg',
        'slopeone', 'pmf', 'bpmf', 'biasedmf', 'nmf',
        'slim', 'bpr',  # 'rankals', 'ranksgd',
        'lrmf',
        'camf_ci', 'camf_cu', # 'camf_c',
        'camf_cuci', 'cslim_c', 'cslim_ci',
        'cslim_cu',  # 'cslim_cuci',
        ## 'camf_ics',
        ##'camf_lcs', 'camf_mcs', 'cslim_ics', 'cslim_lcs',
        ##'cslim_mcs', 'gcslim_ics'
    ]

    slow_recommenders = [
        # 'contextavg', 'itemcontextavg', 'usercontextavg',  # broken without context
        ## 'itemknn',
        ## 'userknn',
        ## 'cptf',
        ## 'gcslim_cc',
        ## 'gcslim_lcs',
        ## 'gcslim_mcs',
        ## 'fm'
    ]

    rating_recommenders = [
        'globalavg', 'useravg', 'itemavg', 'useritemavg',
        # 'contextavg', 'itemcontextavg', 'usercontextavg',
        'itemknn', 'userknn', 'slopeone', 'pmf', 'biasedmf', 'nmf',
        'cptf',
        'camf_ci', 'camf_cu', 'camf_c', 'camf_cuci',
        'camf_ics', 'camf_lcs', 'camf_mcs',
        'fm'
    ]

    rank_recommenders = [
        'globalavg', 'useravg', 'itemavg', 'useritemavg',
        # 'contextavg', 'itemcontextavg', 'usercontextavg',
        'itemknn', 'userknn', 'slopeone', 'pmf', 'bpmf', 'biasedmf', 'nmf',
        'slim', 'bpr',  # 'rankals', 'ranksgd',
        'lrmf',
        'cptf',
        'camf_ci', 'camf_cu', 'camf_c', 'camf_cuci', 'cslim_c', 'cslim_ci',
        'cslim_cu',  # 'cslim_cuci',
        'gcslim_cc',
        # 'camf_ics',
        'camf_lcs', 'camf_mcs', 'cslim_ics', 'cslim_lcs',
        'cslim_mcs', 'gcslim_ics', 'gcslim_lcs', 'gcslim_mcs',
        'fm'
    ]

    rank_only_recommenders = [
        'slim', 'bpr',  # 'rankals', 'ranksgd',
        'lrmf',
        'cslim_c', 'cslim_ci',
        'cslim_cu',  # 'cslim_cuci',
        'gcslim_cc',
        'cslim_ics', 'cslim_lcs',
        'cslim_mcs', 'gcslim_ics', 'gcslim_lcs', 'gcslim_mcs'
    ]

    recommenders = all_recommenders

    print('num recommenders: %d' % len(recommenders))
    index = 1

    for recommender in recommenders:
        print('cycle %d/%d' % (index, len(recommenders)))
        print('Recommender: %s' % recommender)
        Constants.update_properties({'carskit_recommenders': recommender})
        index += 1

        cycle_start = time.time()
        full_cycle()
        cycle_end = time.time()
        cycle_time = cycle_end - cycle_start
        print("Cycle time = %f seconds" % cycle_time)
    analyze_results()


start = time.time()
main()
end = time.time()
total_time = end - start
print("Total time = %f seconds" % total_time)
